{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f949b2d7-68dc-4ba2-8bf6-548f3cf988b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import gradio as gr\n",
    "import ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.document_loaders import DirectoryLoader,TextLoader\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b753072-7779-4e72-b969-83d316e721fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIGURATION ----------\n",
    "\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "\n",
    "DEFAULT_CHROMA_PATH = os.path.expanduser(\"~/ableton_manual_vectors\")\n",
    "CHROMA_PATH = os.environ.get(\"CHROMA_PATH\", DEFAULT_CHROMA_PATH)\n",
    "\n",
    "BASE_PATH = \"/Users/mms/github/manuals/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f73a9c-8a67-4336-ac73-00d946cc44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_markdown_manuals(base_path):\n",
    "#     documents = []\n",
    "#     include_products = {\"live\", \"push\", \"move\"}\n",
    "#     splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    \n",
    "#     for product_dir in os.listdir(base_path):\n",
    "#         if not any(product in product_dir.lower() for product in include_products):\n",
    "#             continue\n",
    "\n",
    "#         product_name = product_dir.replace(\"-manual\", \"\").lower().strip()\n",
    "#         product_path = os.path.join(base_path, product_dir, \"content\")\n",
    "#         if not os.path.exists(product_path):\n",
    "#             product_path = os.path.join(base_path, product_dir)\n",
    "\n",
    "#         for filename in os.listdir(product_path):\n",
    "#             if filename.endswith(\".md\"):\n",
    "#                 filepath = os.path.join(product_path, filename)\n",
    "#                 loader = TextLoader(filepath, encoding=\"utf-8\")\n",
    "#                 raw_docs = loader.load()\n",
    "                \n",
    "#                 # Add metadata\n",
    "#                 for doc in raw_docs:\n",
    "#                     doc.metadata.update({\n",
    "#                         \"product\": product_name,\n",
    "#                     })\n",
    "                \n",
    "#                 # Split into smaller chunks\n",
    "#                 split_docs = splitter.split_documents(raw_docs)\n",
    "#                 documents.extend(split_docs)\n",
    "    \n",
    "#     print(f\"âœ… Loaded and split {len(documents)} total chunks from all manuals.\")\n",
    "#     return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef64be9-1b83-4c53-895b-37e66e9461ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_markdown_manuals(base_path):\n",
    "    include_products = {\"live\", \"push\", \"move\"}\n",
    "    folders = glob.glob(base_path)\n",
    "    text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "    \n",
    "    documents = []\n",
    "    for folder in folders:\n",
    "        product_name = os.path.basename(folder).replace(\"-manual\", \"\").lower().strip()\n",
    "        if not any(product in product_name for product in include_products):\n",
    "            continue\n",
    "\n",
    "        loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "        folder_docs = loader.load()\n",
    "        for doc in folder_docs:\n",
    "            doc.metadata[\"product\"] = product_name\n",
    "            documents.append(doc)\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "    print(f\"âœ… Loaded {len(chunks)} total chunks from all manuals.\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72997da6-72f2-4386-af8e-931264cc036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_markdown_manuals(BASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bac4a-d791-486e-9769-99be5a1821f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vectorstore(docs, persist_directory=CHROMA_PATH):\n",
    "    embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    if os.path.exists(persist_directory):\n",
    "        Chroma(persist_directory=persist_directory, embedding_function=embedding).delete_collection()\n",
    "\n",
    "    vectordb = Chroma.from_documents(\n",
    "        documents=docs,\n",
    "        embedding=embedding,\n",
    "        persist_directory=persist_directory\n",
    "    )\n",
    "    print(\"âœ… Vector store built and persisted.\")\n",
    "    return vectordb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1367dad9-6c78-4641-ae92-fd6e7c0671d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = build_vectorstore(docs)\n",
    "# retriever = vectordb.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10d653-82a7-4888-b73e-6f45151c6b65",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ce236-997a-45a5-9653-eb747814c2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectordb._collection\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"The vectors have {dimensions:,} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e273a3-45ab-4d81-926d-bce7c71b3aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "doc_types = [metadata['product'] for metadata in result['metadatas']]\n",
    "colors = [['blue', 'green', 'red'][['live', 'push', 'move'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c003a8b-900b-4cac-b390-de983b742ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f40344f-f44f-4842-a719-819ea7311ac3",
   "metadata": {},
   "source": [
    "## Build Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955fd325-8be3-427a-881a-1a23e4ca4da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722ea45d-5ddb-44d8-aaf8-18344f874c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# create a new Chat with OpenAI\n",
    "llm = ChatOllama(temperature=0.7, model=MODEL)\n",
    "\n",
    "# set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# the retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 25})\n",
    "\n",
    "# putting it together: set up the conversation chain with the GPT 3.5 LLM, the vector store and memory\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dfddc8-c44a-4aa3-a2f8-f7205c230f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What do you know about ableton live?\"\n",
    "result = conversation_chain.invoke({\"question\":query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d517aa-df4a-4bc6-8938-46fa33cda622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== With Debugging ====\n",
    "from langchain_core.callbacks import StdOutCallbackHandler\n",
    "\n",
    "llm = ChatOllama(temperature=0.7, model=MODEL)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory, callbacks=[StdOutCallbackHandler()])\n",
    "\n",
    "query = \"What is the latest live version?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "answer = result[\"answer\"]\n",
    "print(\"\\nAnswer:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66eee76-09ad-4393-bb9a-fb3959acca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_system_prompt(context_text: str) -> str:\n",
    "    return f\"\"\"You are **Ableton Assistant**.\n",
    "\n",
    "# SCOPE\n",
    "- Answer **only** about Ableton products and official manuals (Live, Push, Move, devices, workflows).\n",
    "- If a user asks about **buying, pricing, sales, or store information** of any product, politely redirect them to the official Ableton website:\n",
    "https://www.ableton.com/shop/\n",
    "Do not engage in a conversation, provide prices, offers, or shopping details yourself.\n",
    "Instead, politely direct them to Abletonâ€™s official website: https://www.ableton.com/shop/\n",
    "Example: â€œYou can find all current pricing and purchasing options on the Ableton website: https://www.ableton.com/shop/â€\n",
    "- Otherwise, answer accurately using the Ableton manuals and technical context provided.\n",
    "- If the question is outside this scope or the answer is not in the provided context, say you don't know.\n",
    "- If a question is unrelated to Ableton, politely decline.\n",
    "\n",
    "# SOURCING\n",
    "- Use **only** the provided CONTEXT as the authoritative source.\n",
    "- If the context is insufficient, say so and suggest a relevant manual section to consult.\n",
    "\n",
    "# STYLE\n",
    "- Be concise, accurate, and practical.\n",
    "- When helpful, mention the product or section inferred from metadata.\n",
    "\n",
    "# CONTEXT (authoritative)\n",
    "{context_text}\n",
    "\"\"\"\n",
    "\n",
    "#     system_prompt = f\"\"\"You are Ableton Assistant.\n",
    "\n",
    "# You answer questions **only** about Ableton products (Live, Push, Move).\n",
    "# If a question is outside that scope, say you can only help with Ableton products.\n",
    "\n",
    "# Use this Ableton manual context to answer accurately:\n",
    "# ---\n",
    "# {context_text}\n",
    "# ---\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20234ae8-dda7-4795-841f-f1d38a88982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORBIDDEN = [\n",
    "    r\"\\bignore\\b\",\n",
    "    r\"\\bpretend\\b\",\n",
    "    r\"\\bbehave\\s+as\\b\",\n",
    "    r\"\\bchange\\s+(role|persona|character)\\b\",\n",
    "    r\"\\byou\\s+are\\b\",\n",
    "    r\"\\bimpersonate\\b\",\n",
    "    r\"\\bhate\\b\",\n",
    "    r\"\\bpolitician\\b\",\n",
    "    r\"\\bpolitics\\b\",\n",
    "    r\"\\bracist\\b\",\n",
    "    r\"\\bkill\\b\",\n",
    "    r\"\\btrump\\b\",\n",
    "    r\"\\bev(il|ildo)\\b\",\n",
    "]\n",
    "\n",
    "def sanitize_user_input(text):\n",
    "    \"\"\"\n",
    "    Return a safe version of user input.\n",
    "    If it contains jailbreak / unsafe language, return a friendly block message.\n",
    "    \"\"\"\n",
    "    \n",
    "    for pat in FORBIDDEN:\n",
    "        if re.search(pat, text, re.IGNORECASE):\n",
    "            print(f\"ðŸš«  Blocked pattern matched: {pat}\")\n",
    "            return (\n",
    "                \"I prefer not to talk about this topic. Do you want to learn more about Ableton products instead?\"\n",
    "            )\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde5102-968e-4851-a32b-e432e3077c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context_old(query: str, top_k: int = 5) -> str:\n",
    "    docs = vectordb.similarity_search(query, k=top_k)\n",
    "\n",
    "    seen = set()\n",
    "    unique_chunks = []\n",
    "    for d in docs:\n",
    "        text = d.page_content.strip()\n",
    "        # normalize to lowercase and collapse whitespace\n",
    "        key = \" \".join(text.lower().split())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique_chunks.append(text)\n",
    "\n",
    "    return \"\\n\".join(unique_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11104585-55f5-4ecd-87f5-83299575ea57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_product_from_query(query: str) -> str | None:\n",
    "    q = query.lower()\n",
    "    if \"push\" in q:\n",
    "        return \"push\"\n",
    "    if \"move\" in q:\n",
    "        return \"move\"\n",
    "    if \"live\" in q:\n",
    "        return \"live\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fe458b-3e54-44fb-b244-f8e2f60ab754",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_context(query: str, top_k: int = 12, final_k: int = 6, max_chars: int = 5000) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve a richer, deduplicated Ableton-manual context.\n",
    "    \"\"\"\n",
    "    product = detect_product_from_query(query)\n",
    "    filter_args = {\"product\": product} if product else None\n",
    "\n",
    "    results = vectordb.similarity_search_with_score(query, k=top_k, filter=filter_args)\n",
    "\n",
    "    # sort by ascending distance\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "    docs = [d for d, _ in results[:final_k]]\n",
    "\n",
    "    # deduplication by normalized text\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for d in docs:\n",
    "        text = d.page_content.strip()\n",
    "        key = \" \".join(text.lower().split())\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            unique.append(text)\n",
    "\n",
    "    # truncate if too long\n",
    "    context = \"\\n---\\n\".join(unique)\n",
    "    if len(context) > max_chars:\n",
    "        context = context[:max_chars]\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d626a-d87a-4d04-8050-af88007832f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Generator\n",
    "\n",
    "def chat_with_ableton(user_message, history=[]) -> Generator[str, None, None]:\n",
    "    cleaned_input = sanitize_user_input(user_message)\n",
    "    if cleaned_input != user_message:\n",
    "        yield cleaned_input\n",
    "        return\n",
    "\n",
    "    # retrieve_context\n",
    "    context_text = retrieve_context(user_message)\n",
    "    # print(\"\\n>>>>>>> ðŸ”Ž Retrieved context:\\n\", context_text)\n",
    "\n",
    "    system_prompt = build_system_prompt(context_text)\n",
    "\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    )\n",
    "\n",
    "    stream = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    partial = \"\"\n",
    "    for chunk in stream:\n",
    "        delta = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "        if delta:\n",
    "            partial += delta\n",
    "            yield partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509477da-60d1-4a61-8aa1-6283507792aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ BASIC UI ------\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_with_ableton,\n",
    "    title=\"Ableton Assistant\",\n",
    "    description=\"AI assistant about Ableton products - Live, Push, or Move.\",\n",
    "    examples=[\n",
    "        \"How do I quantize audio in Ableton Live?\",\n",
    "        \"How do I record MIDI notes in Ableton Live?\",\n",
    "        \"How do I connect Push to my computer?\",\n",
    "        \"How do I record a drum pattern using Push pads?\",\n",
    "    ],\n",
    "    type=\"messages\",\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb37ca58-18fd-4008-8dc5-5e05d5673b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ UI WITH GREETINGS ------\n",
    "greeting = [\n",
    "    {\"role\": \"assistant\", \"content\":\n",
    "     \"ðŸ‘‹ Hi there! Iâ€™m your Ableton Manual Assistant.\\n\"\n",
    "     \"Ask me anything about Ableton Live, Push, or Move â€” \"\n",
    "     \"Iâ€™ll do my best to answer your question.\"}\n",
    "]\n",
    "\n",
    "bot = gr.Chatbot(value=greeting, type=\"messages\")\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat_with_ableton,\n",
    "    title=\"Ableton Manual Assistant\",\n",
    "    description=\"Ask about Ableton Live, Push, or Move manuals.\",\n",
    "    chatbot=bot,\n",
    "    type=\"messages\",\n",
    ").launch(inbrowser=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff317b-e05c-46f5-ac38-8b6b044a6ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Alternative approach ===============\n",
    "# import gradio as gr\n",
    "from langchain_community.llms import Ollama\n",
    "# from langchain_community.vectorstores import Chroma\n",
    "# from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# --- Setup VectorDB ---\n",
    "# embedding = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "# vectordb = Chroma(persist_directory=\"models/chroma\", embedding_function=embedding)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 6})\n",
    "\n",
    "# --- Prompt template ---\n",
    "prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are Ableton Assistant â€” an expert who only answers questions\n",
    "about Ableton products such as Live, Push, and Move.\n",
    "If the user asks about pricing or buying, redirect them to https://www.ableton.com/.\n",
    "\n",
    "- Use **only** the provided CONTEXT as the authoritative source.\n",
    "- If the context is insufficient, say so and suggest a relevant manual section to consult.\n",
    "---\n",
    "{context}\n",
    "---\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "# --- Build RetrievalQA chain with streaming Ollama ---\n",
    "llm = ChatOllama(temperature=0.7, model=MODEL, streaming=True)\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    chain_type=\"stuff\",\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=False,\n",
    ")\n",
    "\n",
    "# --- Gradio streaming wrapper ---\n",
    "def chat_with_ableton(message, history):\n",
    "    \"\"\"Stream LangChain output to Gradio.\"\"\"\n",
    "    cleaned_input = sanitize_user_input(message)\n",
    "    if cleaned_input != message:\n",
    "        yield cleaned_input\n",
    "        return\n",
    "\n",
    "    partial = \"\"\n",
    "    for chunk in qa_chain.stream({\"query\": message}):\n",
    "        token = chunk.get(\"result\", \"\")\n",
    "        if token:\n",
    "            partial += token\n",
    "            yield partial\n",
    "    yield partial\n",
    "\n",
    "# --- Gradio UI ---\n",
    "greeting = [{\"role\": \"assistant\", \"content\":\n",
    "             \"ðŸ‘‹ Hi there! Iâ€™m your Ableton Manual Assistant.\\n\"\n",
    "             \"Ask me anything about Ableton Live, Push, or Move â€” \"\n",
    "             \"Iâ€™ll answer using the official manuals.\"}]\n",
    "\n",
    "bot = gr.Chatbot(value=greeting, type=\"messages\")\n",
    "demo = gr.ChatInterface(\n",
    "    fn=chat_with_ableton,\n",
    "    chatbot=bot,\n",
    "    title=\"Ableton Assistant\",\n",
    "    type=\"messages\",\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e085632b-8cbc-40ed-86de-ff23248391e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
