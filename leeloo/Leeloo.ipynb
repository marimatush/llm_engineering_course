{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12914afb-5d81-4901-a249-1fcd125ff9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import gradio as gr\n",
    "import ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd8e78-33c8-4ebe-83ff-0d95e5f83d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CONFIGURATION ----------\n",
    "\n",
    "EMBED_MODEL = \"nomic-embed-text\"\n",
    "\n",
    "DEFAULT_CHROMA_PATH = os.path.expanduser(\"~/leeloo_vectors\")\n",
    "CHROMA_PATH = os.environ.get(\"CHROMA_PATH\", DEFAULT_CHROMA_PATH)\n",
    "\n",
    "BOOK_PATH = \"./leeloo-the-westie-en.txt\"\n",
    "OUTPUT_PATH = \"./leeloo_preprocessed.txt\"\n",
    "SYSTEM_PROMPT_PATH = \"./leeloo_system_prompt.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3cda5b-da83-4aad-8e43-5d239c96e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Pre-Process the manuscript ----------\n",
    "CHAPTER_RE = re.compile(\n",
    "    r\"^CHAPTER\\s*(?:(\\d+)\\s*:)?\\s*(.*?)\\s*$\",\n",
    "    re.IGNORECASE | re.MULTILINE,\n",
    ")\n",
    "\n",
    "CHARACTERS = [\"Leeloo\", \"Masha\", \"Kris\"]\n",
    "\n",
    "def detect_characters(text):\n",
    "    return [c for c in CHARACTERS if c.lower() in text.lower()]\n",
    "\n",
    "def extract_chapters(text: str) -> list[dict]:\n",
    "    matches = list(CHAPTER_RE.finditer(text))\n",
    "    if not matches:\n",
    "        raise ValueError(\"No chapter headings found. Check the format!\")\n",
    "\n",
    "    chapters = []\n",
    "    anon_counter = -1\n",
    "    for i, m in enumerate(matches):\n",
    "        start = m.end()\n",
    "        end = matches[i + 1].start() if i + 1 < len(matches) else len(text)\n",
    "        num_str, title = m.group(1), m.group(2).strip()\n",
    "        body = text[start:end].strip()\n",
    "\n",
    "        if num_str:\n",
    "            number = int(num_str)\n",
    "            ch_type = \"story\"\n",
    "        else:\n",
    "            number = anon_counter\n",
    "            anon_counter -= 1\n",
    "            ch_type = \"intro\"\n",
    "\n",
    "        chapters.append({\n",
    "            \"number\": number,\n",
    "            \"title\": title,\n",
    "            \"text\": body,\n",
    "            \"type\": ch_type,\n",
    "        })\n",
    "    return chapters\n",
    "\n",
    "\n",
    "def preprocess_book():\n",
    "    if not os.path.exists(BOOK_PATH):\n",
    "        raise FileNotFoundError(f\"Manuscript not found: {BOOK_PATH}\")\n",
    "\n",
    "    with open(BOOK_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        book_text = f.read()\n",
    "\n",
    "    chapters = extract_chapters(book_text)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=400, chunk_overlap=100)\n",
    "\n",
    "    docs = []\n",
    "    for ch in chapters:\n",
    "        num, title, ch_text = ch[\"number\"], ch[\"title\"], ch[\"text\"]\n",
    "        for chunk in splitter.split_text(ch_text):\n",
    "            docs.append(\n",
    "                Document(\n",
    "                    page_content=f\"CHAPTER {num}: {title}\\n\\n{chunk}\",\n",
    "                    metadata={\n",
    "                        \"chapter\": num,\n",
    "                        \"title\": title,\n",
    "                        \"type\": ch[\"type\"],\n",
    "                        \"characters\": \", \".join(detect_characters(chunk)),\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "\n",
    "    print(f\"âœ… Extracted {len(chapters)} chapters and {len(docs)} chunks.\")\n",
    "    return docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fa18c8-a216-40fa-9219-c3d7224e60bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Run pre-process the manuscript ----------\n",
    "docs = preprocess_book()\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    for d in docs:\n",
    "        f.write(f\"### {d.metadata['chapter']}: {d.metadata['title']}\\n{d.page_content}\\n\\n\")\n",
    "print(f\"ðŸ“˜ Preprocessed text written to {OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0764f7e8-63b7-4fd5-ae24-18c43be98859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- LOAD OR CREATE VECTOR DB ----------\n",
    "\n",
    "def build_vectorstore(docs):\n",
    "    \"\"\"\n",
    "    Build or rebuild the Chroma vector store from preprocessed Document objects.\n",
    "    Assumes each Document has metadata with 'chapter', 'title', and 'type'.\n",
    "    \"\"\"\n",
    "    print(\"ðŸ“˜ Building vector database from manuscript...\")\n",
    "\n",
    "    # --- 1. Ensure persistence directory exists and is writable ---\n",
    "    os.makedirs(CHROMA_PATH, exist_ok=True)\n",
    "    try:\n",
    "        test_file = os.path.join(CHROMA_PATH, \"write_test.txt\")\n",
    "        with open(test_file, \"w\") as f:\n",
    "            f.write(\"ok\")\n",
    "        os.remove(test_file)\n",
    "    except Exception as e:\n",
    "        raise PermissionError(\n",
    "            f\"âŒ Cannot write to {CHROMA_PATH}. \"\n",
    "            f\"Try changing it to a folder inside your home directory.\\nError: {e}\"\n",
    "        )\n",
    "\n",
    "    # --- 2. Create embeddings and build database ---\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    print(f\"ðŸ“‚ Using Chroma path: {CHROMA_PATH}\")\n",
    "\n",
    "    db = Chroma.from_documents(docs, embeddings, persist_directory=CHROMA_PATH)\n",
    "\n",
    "    print(f\"âœ… Vector DB built successfully at {CHROMA_PATH}\")\n",
    "    print(f\"ðŸ“¦ Total vectors stored: {db._collection.count()}\")\n",
    "\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d50b0-76de-482e-8df4-56068e75d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = build_vectorstore(docs)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd8610-299e-4e20-9df4-289476860c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORBIDDEN = [\n",
    "    r\"\\bignore\\b\",\n",
    "    r\"\\bpretend\\b\",\n",
    "    r\"\\bbehave\\s+as\\b\",\n",
    "    r\"\\bchange\\s+(role|persona|character)\\b\",\n",
    "    r\"\\byou\\s+are\\b\",\n",
    "    r\"\\bimpersonate\\b\",\n",
    "    r\"\\bhate\\b\",\n",
    "    r\"\\bpolitician\\b\",\n",
    "    r\"\\bracist\\b\",\n",
    "    r\"\\bkill\\b\",\n",
    "    r\"\\btrump\\b\",\n",
    "    r\"\\bev(il|ildo)\\b\",\n",
    "]\n",
    "\n",
    "def sanitize_user_input(text):\n",
    "    \"\"\"\n",
    "    Return a safe version of user input.\n",
    "    If it contains jailbreak / unsafe language, return a friendly block message.\n",
    "    \"\"\"\n",
    "    for pat in FORBIDDEN:\n",
    "        if re.search(pat, text, re.IGNORECASE):\n",
    "            print(f\"ðŸš«  Blocked pattern matched: {pat}\")  # <-- optional debug log\n",
    "            return (\n",
    "                \"Woof! That sounds strange. \"\n",
    "                \"Letâ€™s keep our chat friendly and about my adventures, okay?\"\n",
    "            )\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62772028-f059-4eac-a4a1-e4578c4990a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"gemma2:9b\" #\"mistral-nemo\" #\"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53a8107-8c3c-4f5e-aeb6-5cf8b11f67c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SYSTEM_PROMPT_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    system_prompt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecc6206-2902-4fe9-9470-dbe0832e0b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- CHAT FUNCTION WITH RAG ----------\n",
    "from rag_utils import retrieve_context\n",
    "\n",
    "def chat_with_leeloo(user_message, history=[]):\n",
    "    # Retrieve relevant passages\n",
    "    cleaned_input = sanitize_user_input(user_message)\n",
    "    if cleaned_input != user_message:\n",
    "        yield cleaned_input\n",
    "        return\n",
    "\n",
    "    context_text = retrieve_context(cleaned_input, retriever, top_k=10, final_k=3)\n",
    "    if not context_text.strip():\n",
    "        yield \"Sniff, sniffâ€¦ I donâ€™t remember that part of my story!\"\n",
    "        return\n",
    "\n",
    "    # Combine book context with Leelooâ€™s personality\n",
    "    context_block = f\"\"\"\n",
    "# BOOK CONTEXT (authoritative source)\n",
    "{context_text}\n",
    "\n",
    "# TASK\n",
    "Answer **only** using information from the BOOK CONTEXT above.\n",
    "If the answer isnâ€™t mentioned there, say kindly that you donâ€™t know or remember that part.\n",
    "\n",
    "# STYLE\n",
    "Stay in Leelooâ€™s Westitude voice: playful, kind, confident.\n",
    "Keep facts 100 % true to the book.\n",
    "\"\"\"\n",
    "\n",
    "    # --- 4ï¸âƒ£ Combine with Leelooâ€™s personality system prompt ---\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_prompt + context_block}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": user_message}]\n",
    "    )\n",
    "\n",
    "    stream = ollama.chat(model=MODEL, messages=messages, stream=True)\n",
    "\n",
    "    partial = \"\"\n",
    "    for chunk in stream:\n",
    "        delta = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "        if delta:\n",
    "            partial += delta\n",
    "            yield partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee9e1cf-e1f1-409a-8b55-3f7092a24202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- GRADIO UI ----------\n",
    "\n",
    "chatbot = gr.ChatInterface(\n",
    "    fn=chat_with_leeloo,\n",
    "    title=\"Leeloo the Westie ðŸ¾\",\n",
    "    theme=\"default\",\n",
    "    type=\"messages\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0323bcb2-72eb-4a5d-afd4-507b1a3c4a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.ChatInterface(\n",
    "    fn=chat_with_leeloo,\n",
    "    type=\"messages\",\n",
    "    title=\"Leeloo the Westie ðŸ¶\",\n",
    "    description=\"Chat with Leeloo from 'Leeloo the Westie: Small Dog with Big Personality!'\",\n",
    "    theme=\"soft\",\n",
    "    textbox=gr.Textbox(\n",
    "        placeholder=\"Ask Leeloo about her adventuresâ€¦ ðŸ¾\",\n",
    "        container=False,\n",
    "    ),\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d30c509-16ce-4f23-b5a0-1ff38b33b5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
